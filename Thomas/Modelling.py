# ---
# jupyter:
#   jupytext:
#     text_representation:
#       extension: .py
#       format_name: light
#       format_version: '1.5'
#       jupytext_version: 1.13.0
#   kernelspec:
#     display_name: Python 3
#     language: python
#     name: python3
# ---

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
import lightgbm as lgb
import graphviz
df = pd.read_csv('../Dataset/Malware_Classification.csv/Malware_Classification.csv')

features_tree_based = ['Characteristics',
 'DllCharacteristics',
 'SectionsMaxEntropy',
 'MajorSubsystemVersion',
 'Subsystem',
 'ResourcesMaxEntropy',
 'ResourcesMinEntropy',
 'VersionInformationSize',
 'ImageBase',
 'SizeOfOptionalHeader',
 'MajorOperatingSystemVersion',
 'SectionsMinEntropy',
 'SectionsMeanEntropy',
 'CheckSum',
 'SectionsNb',
 'MinorLinkerVersion',
 'ResourcesMeanEntropy',
 'MinorOperatingSystemVersion',
 'SizeOfStackReserve',
 'ResourcesMinSize']

feature_KBest_Based = ['ImageBase',
 'CheckSum',
 'SizeOfStackReserve',
 'SizeOfUninitializedData',
 'LoadConfigurationSize',
 'SizeOfInitializedData',
 'LoaderFlags',
 'BaseOfCode',
 'ResourcesMinSize',
 'AddressOfEntryPoint',
 'SizeOfImage',
 'SizeOfHeapCommit',
 'SectionMaxVirtualsize',
 'SectionsMinVirtualsize',
 'SizeOfCode',
 'BaseOfData',
 'DllCharacteristics',
 'SectionAlignment',
 'SectionsMeanVirtualsize',
 'Characteristics']

y = df['legitimate']
X = df[feature_KBest_Based]

X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.3, stratify = df['legitimate'])

print('percentage of stratify split')
print('test')
display((y_test.value_counts()/y_test.value_counts().sum())*100)
print('train')
display((y_train.value_counts()/y_train.value_counts().sum())*100)


lgb_train = lgb.Dataset(X_train, y_train)
lgb_test = lgb.Dataset(X_test, y_test, reference=lgb_train)
params = {
    'num_leaves': 10,
    'metric': ['auc'],
    'verbose': -1
}
evals_result = {}  # to record eval results for plotting
gbm = lgb.train(params,
                lgb_train,
                num_boost_round=100,
                valid_sets=[lgb_train, lgb_test],
                feature_name=list(X_train.columns),#[f'f{i + 1}' for i in range(X_train.shape[-1])],#[X_train.columns],
                evals_result=evals_result,
                verbose_eval=10)


def render_metric(metric_name):
    ax = lgb.plot_metric(evals_result, metric=metric_name, figsize=(10, 5))
    plt.show()


render_metric(params['metric'][0])


def render_plot_importance(importance_type, max_features=10,
                           ignore_zero=True, precision=3):
    ax = lgb.plot_importance(gbm, importance_type=importance_type,
                             max_num_features=max_features,
                             ignore_zero=ignore_zero, figsize=(12, 8),
                             precision=precision)
    plt.show()


render_plot_importance(importance_type='split')


# +

def render_tree(tree_index, show_info, precision=3):
    show_info = None if 'None' in show_info else show_info
    return lgb.create_tree_digraph(gbm, tree_index=tree_index,
                                   show_info=show_info, precision=precision)
# -


