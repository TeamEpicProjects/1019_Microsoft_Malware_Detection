# ---
# jupyter:
#   jupytext:
#     text_representation:
#       extension: .py
#       format_name: light
#       format_version: '1.5'
#       jupytext_version: 1.13.0
#   kernelspec:
#     display_name: Python 3
#     language: python
#     name: python3
# ---

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
import lightgbm as lgb
from functools import partial
import optuna
import graphviz
from sklearn.metrics import recall_score
from sklearn.model_selection import KFold
df = pd.read_csv('../Dataset/Malware_Classification.csv/Malware_Classification.csv')

# +
best_params_LGBoost = {'lambda_l1': 9.366835026491083e-07,
 'lambda_l2': 0.0005957622097980031, 'num_leaves': 219,
 'feature_fraction': 0.46353549445063746,
 'bagging_fraction': 0.7893268192199716, 'bagging_freq': 6, 
 'min_child_samples': 75}

features_tree_based = ['Characteristics',
 'DllCharacteristics',
 'SectionsMaxEntropy',
 'MajorSubsystemVersion',
 'Subsystem',
 'ResourcesMaxEntropy',
 'ResourcesMinEntropy',
 'VersionInformationSize',
 'ImageBase',
 'SizeOfOptionalHeader',
 'MajorOperatingSystemVersion',
 'SectionsMinEntropy',
 'SectionsMeanEntropy',
 'CheckSum',
 'SectionsNb',
 'MinorLinkerVersion',
 'ResourcesMeanEntropy',
 'MinorOperatingSystemVersion',
 'SizeOfStackReserve',
 'ResourcesMinSize']
# -

from sklearn.preprocessing import StandardScaler
ssc = StandardScaler()

kf = KFold(n_splits = 5, shuffle = True)
df['kfold'] = -1
for fold, (train_indices,valid_indices) in enumerate(kf.split(X = df)):
    df.loc[valid_indices, 'kfold'] = fold

recall_list = []
for fold in range(5):
    df_req_train = df[df.kfold != fold]
    df_req_test = df[df.kfold == fold]
    
    X_train = df_req_train[features_tree_based]
    y_train = df_req_train.legitimate
    
    X_test = df_req_test[features_tree_based]
    y_test = df_req_test.legitimate
    
    ssc = StandardScaler()
    ssc.fit_transform(X_train)
    ssc.transform(X_test)
    
    gbm = lgb.LGBMClassifier()
    gbm.set_params(**best_params_LGBoost, random_state = fold) 
    gbm.fit(X_train, y_train)\
    
    yhat = gbm.predict(X_test)
    yhat = yhat.round(0)
    
    recall = recall_score(yhat,y_test)
    recall_list.append(recall)

recall_list.mean()

# !jupytext --to py Kfold.ipynb


